{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fd9b20-e765-474f-9beb-69e9e0c70d27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import tarfile\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as tt\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e348c3d1-4983-4531-900c-f5e1d152e939",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Download data, normalize and apply transforms\n",
    "\n",
    "stats = ((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "\n",
    "train_tfms = tt.Compose([tt.RandomCrop(32, padding=4, padding_mode='reflect'),tt.RandomHorizontalFlip(),tt.ToTensor(),tt.Normalize(*stats,inplace=True)])\n",
    "valid_tfms = tt.Compose([tt.ToTensor(), tt.Normalize(*stats,inplace=True)])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=train_tfms)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=valid_tfms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e0ecfc-36c2-4009-9b6c-593719eedfdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Prepare train and test data loader\n",
    "\n",
    "batch_size = 200\n",
    "train_dl = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=3,pin_memory=True)\n",
    "valid_dl = torch.utils.data.DataLoader(testset, batch_size=batch_size*2,\n",
    "                                         shuffle=False, num_workers=3,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7276e5d-ecfc-4703-93bf-87aff736ebec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#use cuda if available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e396ecee-59e7-4362-bdcb-14a1bf484daa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def conv_block(in_channels, out_channels, pool=False):\n",
    "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1,bias=False), \n",
    "              nn.BatchNorm2d(out_channels), \n",
    "              nn.ReLU(inplace=True)]\n",
    "    if pool: layers.append(nn.MaxPool2d(2))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "#Adds a randomly sampled noise from a gaussian distribution to a standardized input tensor\n",
    "class AddNoise(nn.Module):\n",
    "    def __init__(self, mean=0, std=1):\n",
    "        super(AddNoise, self).__init__()\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "    \n",
    "    def to_device(self, device):\n",
    "        # Move the internal state (mean and std) to the specified device\n",
    "        self.mean = torch.tensor(self.mean, device=device)\n",
    "        self.std = torch.tensor(self.std, device=device)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        noise = torch.randn(x.size(),device=device) * self.std + self.mean\n",
    "        return x+noise\n",
    "\n",
    "#Resnet 9 architecture for teacher without noise\n",
    "class Net1(nn.Module):\n",
    "    def __init__(self,in_channels,num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=3, padding=1,bias = False)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(64)\n",
    "        self.add_noise = AddNoise()\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1,bias=False)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(128)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.res1 = nn.Sequential(conv_block(128, 128),conv_block(128, 128))\n",
    "        self.res1conv1 = nn.Conv2d(128, 128, kernel_size=3, padding=1,bias=False)\n",
    "        self.res1batchnorm1 = nn.BatchNorm2d(128)\n",
    "        self.res1conv2 = nn.Conv2d(128, 128, kernel_size=3, padding=1,bias=False)\n",
    "        self.res1batchnorm2 = nn.BatchNorm2d(128)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(256)\n",
    "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1,bias=False)\n",
    "        self.batchnorm4 = nn.BatchNorm2d(512)\n",
    "        self.res2 = nn.Sequential(conv_block(512, 512),conv_block(512, 512))\n",
    "        self.res2conv1 = nn.Conv2d(512, 512, kernel_size=3, padding=1,bias=False)\n",
    "        self.res2batchnorm1 = nn.BatchNorm2d(512)\n",
    "        self.res2conv2 = nn.Conv2d(512, 512, kernel_size=3, padding=1,bias=False)\n",
    "        self.res2batchnorm2 = nn.BatchNorm2d(512)\n",
    "        self.classifier = nn.Sequential(nn.MaxPool2d(4), \n",
    "                                        nn.Flatten(), \n",
    "                                        nn.Linear(512, num_classes))        \n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.batchnorm1(self.conv1(x)))\n",
    "        x = (x-torch.mean(x))/(torch.std(x))\n",
    "        x = self.pool(F.relu(self.batchnorm2(self.conv2(x))))\n",
    "        x = (x-torch.mean(x))/(torch.std(x))\n",
    "        y = x\n",
    "        x = F.relu(self.res1batchnorm1(self.res1conv1(x)))\n",
    "        x = (x-torch.mean(x))/(torch.std(x))\n",
    "        x = F.relu(self.res1batchnorm2(self.res1conv2(x)))\n",
    "        x = (x-torch.mean(x))/(torch.std(x))\n",
    "        x = x+y\n",
    "        x = self.pool(F.relu(self.batchnorm3(self.conv3(x))))\n",
    "        x = (x-torch.mean(x))/(torch.std(x))\n",
    "        x = self.pool(F.relu(self.batchnorm4(self.conv4(x))))\n",
    "        x = (x-torch.mean(x))/(torch.std(x))\n",
    "        z = x\n",
    "        x = F.relu(self.res2batchnorm1(self.res2conv1(x)))\n",
    "        x = (x-torch.mean(x))/(torch.std(x))\n",
    "        x = F.relu(self.res2batchnorm2(self.res2conv2(x)))\n",
    "        x = (x-torch.mean(x))/(torch.std(x))\n",
    "        x = x+z\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "        \n",
    "#Resnet 9 architecture for student with noise   \n",
    "class Net2(nn.Module):\n",
    "    def __init__(self,in_channels,num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=3, padding=1,bias = False)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(64)\n",
    "        self.add_noise = AddNoise()\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1,bias=False)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(128)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.res1 = nn.Sequential(conv_block(128, 128),conv_block(128, 128))\n",
    "        self.res1conv1 = nn.Conv2d(128, 128, kernel_size=3, padding=1,bias=False)\n",
    "        self.res1batchnorm1 = nn.BatchNorm2d(128)\n",
    "        self.res1conv2 = nn.Conv2d(128, 128, kernel_size=3, padding=1,bias=False)\n",
    "        self.res1batchnorm2 = nn.BatchNorm2d(128)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(256)\n",
    "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1,bias=False)\n",
    "        self.batchnorm4 = nn.BatchNorm2d(512)\n",
    "        self.res2 = nn.Sequential(conv_block(512, 512),conv_block(512, 512))\n",
    "        self.res2conv1 = nn.Conv2d(512, 512, kernel_size=3, padding=1,bias=False)\n",
    "        self.res2batchnorm1 = nn.BatchNorm2d(512)\n",
    "        self.res2conv2 = nn.Conv2d(512, 512, kernel_size=3, padding=1,bias=False)\n",
    "        self.res2batchnorm2 = nn.BatchNorm2d(512)\n",
    "        self.classifier = nn.Sequential(nn.MaxPool2d(4), \n",
    "                                        nn.Flatten(), \n",
    "                                        nn.Linear(512, num_classes))        \n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.batchnorm1(self.conv1(x)))\n",
    "        x = (x-torch.mean(x))/(torch.std(x))\n",
    "        x = self.add_noise(x)\n",
    "        x = self.pool(F.relu(self.batchnorm2(self.conv2(x))))\n",
    "        x = (x-torch.mean(x))/(torch.std(x))\n",
    "        x = self.add_noise(x)\n",
    "        y = x\n",
    "        x = F.relu(self.res1batchnorm1(self.res1conv1(x)))\n",
    "        x = (x-torch.mean(x))/(torch.std(x))\n",
    "        x = self.add_noise(x)\n",
    "        x = F.relu(self.res1batchnorm2(self.res1conv2(x)))\n",
    "        x = (x-torch.mean(x))/(torch.std(x))\n",
    "        x = self.add_noise(x)\n",
    "        x = x+y\n",
    "        x = self.pool(F.relu(self.batchnorm3(self.conv3(x))))\n",
    "        x = (x-torch.mean(x))/(torch.std(x))\n",
    "        x = self.add_noise(x)\n",
    "        x = self.pool(F.relu(self.batchnorm4(self.conv4(x))))\n",
    "        x = (x-torch.mean(x))/(torch.std(x))\n",
    "        x = self.add_noise(x)\n",
    "        z = x\n",
    "        x = F.relu(self.res2batchnorm1(self.res2conv1(x)))\n",
    "        x = (x-torch.mean(x))/(torch.std(x))\n",
    "        x = self.add_noise(x)\n",
    "        x = F.relu(self.res2batchnorm2(self.res2conv2(x)))\n",
    "        x = (x-torch.mean(x))/(torch.std(x))\n",
    "        x = self.add_noise(x)\n",
    "        x = x+z\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "net1 = Net1(3,10)\n",
    "net2 = Net2(3,10)\n",
    "net1 = net1.to(device)\n",
    "net2 = net2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a9ae5b-68ed-4e4b-ac8b-0390a5f42a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the pretrained weights for clean baseline network \n",
    "net1.load_state_dict(torch.load('teacher_30epochs_pre.pth'))\n",
    "net2.load_state_dict(torch.load('teacher_30epochs_pre.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc807a6-c945-4fbc-9cca-690ae7fa3658",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the weights fixed for the teacher network\n",
    "for param in net1.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110eaaec-7962-4663-aba4-2fb400d6b5a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "max_lr = 0.005\n",
    "grad_clip = 0.1\n",
    "weight_decay = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8f652a-16e3-44ca-bc19-628133a10984",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "criterion1 = nn.CrossEntropyLoss()\n",
    "criterion2 = nn.CrossEntropyLoss()\n",
    "optimizer2 = optim.Adam(net2.parameters(), lr=max_lr, weight_decay = weight_decay)\n",
    "scheduler2 = optim.lr_scheduler.OneCycleLR(optimizer2, max_lr, epochs=epochs,steps_per_epoch=len(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd08683-c75c-453c-9f40-b2880d4453af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Function to get learning rate during training\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "    \n",
    "T = 6 #temperature of distillation\n",
    "training_time = 0\n",
    "alpha = 1 #balance between hard and soft targets\n",
    "\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    \n",
    "    start_time = time.perf_counter()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    lrs = []\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    for i, data in enumerate(train_dl, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer2.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs1 = net1(inputs)\n",
    "        outputs1_prob = F.softmax(outputs1/T, dim=1)\n",
    "        outputs2 = net2(inputs)\n",
    "        outputs2_prob = F.softmax(outputs2, dim=1)\n",
    "        outputs2_prob_T = F.softmax(outputs2/T, dim=1)\n",
    "        loss_student_hard = criterion1(outputs2_prob, labels)\n",
    "        loss_student_soft = criterion2(outputs2_prob_T, outputs1_prob)\n",
    "        loss =loss_student_hard+alpha*(T**2)*(loss_student_soft)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_value_(net2.parameters(), grad_clip)\n",
    "        optimizer2.step()\n",
    "        lrs.append(get_lr(optimizer2))\n",
    "        scheduler2.step()\n",
    "        \n",
    "        # Calculate training accuracy\n",
    "        _, predicted = torch.max(outputs2, 1)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "        training_acc = (correct_predictions/total_predictions)*100\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 50 == 49:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 50:.3f} learning rate: {lrs[i]} training accuracy: {training_acc:.3f}')\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    training_time += time.perf_counter()-start_time\n",
    "\n",
    "print(f'Finished Training, Training time: {training_time}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a9f387-12b2-440b-8226-6b76bb4ad741",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in valid_dl:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = net2(images) \n",
    "\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f} %')    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
